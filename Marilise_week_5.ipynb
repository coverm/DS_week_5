{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165166dd",
   "metadata": {},
   "source": [
    "# DS Automation Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195af74",
   "metadata": {},
   "source": [
    "Using our prepared churn data from week 2:\n",
    "- use TPOT to find an ML algorithm that performs best on the data\n",
    "    - Choose a metric you think is best to use for finding the best model; by default, it is accuracy but it could be AUC, precision, recall, etc. The week 3 FTE has some information on these different metrics.\n",
    "    - REMEMBER: TPOT only finds the optimized processing pipeline and model. It doesn't create the model. \n",
    "        - You can use `tpot.export('my_model_name.py')` (assuming you called your TPOT object tpot) and it will save a Python template with an example of the optimized pipeline. \n",
    "        - Use the template code saved from the `export()` function in your program.\n",
    "- create a Python script/file/module using code from the exported template above that\n",
    "    - create a function that takes a pandas dataframe as an input and returns the probability of churn for each row in the dataframe\n",
    "    - your Python file/function should print out the predictions for new data (new_churn_data.csv)\n",
    "    - the true values for the new data are [1, 0, 0, 1, 0] if you're interested\n",
    "- test your Python module and function with the new data, new_churn_data.csv\n",
    "- write a short summary of the process and results at the end of this notebook\n",
    "- upload this Jupyter Notebook and Python file to a Github repository, and turn in a link to the repository in the week 5 assignment dropbox\n",
    "\n",
    "*Optional* challenges:\n",
    "- return the probability of churn for each new prediction, and the percentile where that prediction is in the distribution of probability predictions from the training dataset (e.g. a high probability of churn like 0.78 might be at the 90th percentile)\n",
    "- use other autoML packages, such as TPOT, H2O, MLBox, etc, and compare performance and features with pycaret\n",
    "- create a class in your Python module to hold the functions that you created\n",
    "- accept user input to specify a file using a tool such as Python's `input()` function, the `click` package for command-line arguments, or a GUI\n",
    "- Use the unmodified churn data (new_unmodified_churn_data.csv) in your Python script. This will require adding the same preprocessing steps from week 2 since this data is like the original unmodified dataset from week 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aef558",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Import necessary library</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "476ed965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc768fc8",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Import sklearn</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e30b1dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import make_pipeline, make_union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27048213",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Import TPOTClassifier</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba91169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from tpot.builtins import StackingEstimator\n",
    "from tpot.export_utils import set_param_recursive\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import timeit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bcf162",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Import other necessary library</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b414aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyexpat import features\n",
    "from random import random\n",
    "from tkinter.tix import COLUMN\n",
    "from xml.dom.xmlbuilder import DOMEntityResolver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47753af",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Loading data file</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3787a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7032 entries, 7590-VHVEG to 3186-AJIEK\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   tenure                     7032 non-null   int64  \n",
      " 1   PhoneService               7032 non-null   int64  \n",
      " 2   Contract                   7032 non-null   int64  \n",
      " 3   PaymentMethod              7032 non-null   int64  \n",
      " 4   MonthlyCharges             7032 non-null   float64\n",
      " 5   TotalCharges               7032 non-null   float64\n",
      " 6   Churn                      7032 non-null   int64  \n",
      " 7   tenure_TotalCharges_ratio  7032 non-null   float64\n",
      "dtypes: float64(3), int64(5)\n",
      "memory usage: 494.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('prepped_churn_data.csv',index_col='customerID')\n",
    "df #df could be dangerous if file too big\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3046c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#might not need this -- but just in case\n",
    "df['tenure'] = df['tenure'].apply(lambda x: float())\n",
    "df['PhoneService'] = df['PhoneService'].apply(lambda x: float())\n",
    "df['Contract'] = df['Contract'].apply(lambda x: float())\n",
    "df['PaymentMethod'] = df['PaymentMethod'].apply(lambda x: float())\n",
    "df['MonthlyCharges'] = df['MonthlyCharges'].apply(lambda x: float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21cf553a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tenure                       float64\n",
      "PhoneService                 float64\n",
      "Contract                     float64\n",
      "PaymentMethod                float64\n",
      "MonthlyCharges               float64\n",
      "TotalCharges                 float64\n",
      "Churn                          int64\n",
      "tenure_TotalCharges_ratio    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e117bdc",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">TPOT Loading data file & printing contents & diving data into train and test</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f81bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      customerID  tenure  PhoneService  Contract  PaymentMethod  \\\n",
      "0     7590-VHVEG       1             0         0              0   \n",
      "1     5575-GNVDE      34             1         1              1   \n",
      "2     3668-QPYBK       2             1         0              1   \n",
      "3     7795-CFOCW      45             0         1              2   \n",
      "4     9237-HQITU       2             1         0              0   \n",
      "...          ...     ...           ...       ...            ...   \n",
      "7027  6840-RESVB      24             1         1              1   \n",
      "7028  2234-XADUH      72             1         1              3   \n",
      "7029  4801-JZAZL      11             0         0              0   \n",
      "7030  8361-LTMKD       4             1         0              1   \n",
      "7031  3186-AJIEK      66             1         2              2   \n",
      "\n",
      "      MonthlyCharges  TotalCharges  Churn  tenure_TotalCharges_ratio  \n",
      "0              29.85         29.85      0                   0.033501  \n",
      "1              56.95       1889.50      0                   0.017994  \n",
      "2              53.85        108.15      1                   0.018493  \n",
      "3              42.30       1840.75      0                   0.024447  \n",
      "4              70.70        151.65      1                   0.013188  \n",
      "...              ...           ...    ...                        ...  \n",
      "7027           84.80       1990.50      0                   0.012057  \n",
      "7028          103.20       7362.90      0                   0.009779  \n",
      "7029           29.60        346.45      0                   0.031751  \n",
      "7030           74.40        306.60      1                   0.013046  \n",
      "7031          105.65       6844.50      0                   0.009643  \n",
      "\n",
      "[7032 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "tpot_data =  pd.read_csv('prepped_churn_data.csv')\n",
    "print(tpot_data)\n",
    "features = tpot_data.drop(['customerID','Churn'], axis=1)\n",
    "target = tpot_data['Churn']\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, target, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2413b026",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Initiating TPOT Classification and exporting parameters</span>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85809de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbe6ef083064039aa6bac34f6ac885c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.796171119724453\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.7967398401035999\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.7969299531462181\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.7969299531462181\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.7980668543216094\n",
      "\n",
      "Best pipeline: RandomForestClassifier(FastICA(input_matrix, tol=0.2), bootstrap=True, criterion=gini, max_features=0.2, min_samples_leaf=8, min_samples_split=4, n_estimators=100)\n",
      "0.7918088737201365\n",
      "CPU times: total: 1min 13s\n",
      "Wall time: 7min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, n_jobs=-1, random_state=42)\n",
    "tpot.fit(training_features, training_target)\n",
    "print(tpot.score(testing_features, testing_target))\n",
    "tpot.export('churn_data_best_class_model.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70378255",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Using parameter from Classification py file</span>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8308480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tpot.export_utils import set_param_recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ae90aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average CV score on the training set was: 0.7980668543216094\n",
    "exported_pipeline = make_pipeline(\n",
    "    FastICA(tol=0.2),\n",
    "    RandomForestClassifier(bootstrap=True, criterion=\"gini\", max_features=0.2, min_samples_leaf=8, min_samples_split=4, n_estimators=100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05bdd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f0a943a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('fastica', FastICA(random_state=42, tol=0.2)),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(max_features=0.2, min_samples_leaf=8,\n",
       "                                        min_samples_split=4,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exported_pipeline.fit(training_features, training_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "328d2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = exported_pipeline.predict(testing_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fa4934",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Import TPOT Regressor</span>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5a93bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the usual packages\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timeit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a69d39c",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Load data and divide the data into train and test</span>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e61077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_data =  pd.read_csv('prepped_churn_data.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_features, training_target, train_size=0.8, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30c6854",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Initializing TPOT Regression and exporting parameter</span>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46c32267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9453596ebb1e4cf8aea5691bd12d3109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.2860959679646081\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.2879225707996487\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.28924936746591035\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.2896377923505735\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.2896377923505735\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(input_matrix, bootstrap=True, max_features=0.7500000000000001, min_samples_leaf=7, min_samples_split=19, n_estimators=100)\n",
      "0.2703730539144147\n",
      "CPU times: total: 48.3 s\n",
      "Wall time: 5min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tpot = TPOTRegressor(generations=5, population_size=50, verbosity=2, n_jobs=-1, scoring='r2', random_state=42)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('churn_data_best_reg_model.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e96f4c",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Using parameter from Regression py file</span>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7a2ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union #not in file \n",
    "from tpot.builtins import stacking_estimator #not in file \n",
    "from tpot.export_utils import set_param_recursive #not in file \n",
    "from xgboost import XGBRegressor #not in file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65bc760",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Loading data</span>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7bc12b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_data =  pd.read_csv('new_churn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "381ff34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#might not need this -- but just in case\n",
    "tpot_data['customerID'] = tpot_data['customerID'].apply(lambda x: float())\n",
    "tpot_data['tenure'] = tpot_data['tenure'].astype(float)\n",
    "tpot_data['PhoneService'] = tpot_data['PhoneService'].astype(float)\n",
    "tpot_data['Contract'] = tpot_data['Contract'].astype(float)\n",
    "tpot_data['PaymentMethod'] = tpot_data['PaymentMethod'].astype(float)\n",
    "tpot_data['MonthlyCharges'] = tpot_data['MonthlyCharges'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ab1e2",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Training & Testing </span>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2b34754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tpot_data.drop('customerID', axis=1)\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['customerID'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdc3047",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Using exported pipeline automation parameters</span>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db3f315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   customerID         5 non-null      float64\n",
      " 1   tenure             5 non-null      float64\n",
      " 2   PhoneService       5 non-null      float64\n",
      " 3   Contract           5 non-null      float64\n",
      " 4   PaymentMethod      5 non-null      float64\n",
      " 5   MonthlyCharges     5 non-null      float64\n",
      " 6   TotalCharges       5 non-null      float64\n",
      " 7   charge_per_tenure  5 non-null      float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 448.0 bytes\n"
     ]
    }
   ],
   "source": [
    "tpot_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a78a842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#might not need this -- but just in case\n",
    "tpot_data['customerID'] = tpot_data['customerID'].apply(lambda x: float())\n",
    "tpot_data['tenure'] = tpot_data['tenure'].astype(float)\n",
    "tpot_data['PhoneService'] = tpot_data['PhoneService'].astype(float)\n",
    "tpot_data['Contract'] = tpot_data['Contract'].astype(float)\n",
    "tpot_data['PaymentMethod'] = tpot_data['PaymentMethod'].astype(float)\n",
    "tpot_data['MonthlyCharges'] = tpot_data['MonthlyCharges'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7161935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average CV score on the training set was: 0.2896377923505735\n",
    "exported_pipeline = ExtraTreesRegressor(bootstrap=True, max_features=0.7500000000000001, min_samples_leaf=7, min_samples_split=19, n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fa19df",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">Just making sure of data integrity</span>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f714c657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   tenure             5 non-null      int64  \n",
      " 1   PhoneService       5 non-null      int64  \n",
      " 2   Contract           5 non-null      int64  \n",
      " 3   PaymentMethod      5 non-null      int64  \n",
      " 4   MonthlyCharges     5 non-null      float64\n",
      " 5   TotalCharges       5 non-null      float64\n",
      " 6   charge_per_tenure  5 non-null      float64\n",
      "dtypes: float64(3), int64(4)\n",
      "memory usage: 408.0 bytes\n"
     ]
    }
   ],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e399c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_data['customerID'] = tpot_data['customerID'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e75d2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#might not need this -- but just in case\n",
    "#df['customerID'] = df['customerID'].apply(lambda x: float())\n",
    "tpot_data['tenure'] = tpot_data['tenure'].astype(float)\n",
    "tpot_data['PhoneService'] = tpot_data['PhoneService'].astype(float)\n",
    "tpot_data['Contract'] = tpot_data['Contract'].astype(float)\n",
    "tpot_data['PaymentMethod'] = tpot_data['PaymentMethod'].astype(float)\n",
    "tpot_data['MonthlyCharges'] = tpot_data['MonthlyCharges'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5bca1949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   customerID         5 non-null      float64\n",
      " 1   tenure             5 non-null      float64\n",
      " 2   PhoneService       5 non-null      float64\n",
      " 3   Contract           5 non-null      float64\n",
      " 4   PaymentMethod      5 non-null      float64\n",
      " 5   MonthlyCharges     5 non-null      float64\n",
      " 6   TotalCharges       5 non-null      float64\n",
      " 7   charge_per_tenure  5 non-null      float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 448.0 bytes\n"
     ]
    }
   ],
   "source": [
    "tpot_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "532d6e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID           float64\n",
      "tenure               float64\n",
      "PhoneService         float64\n",
      "Contract             float64\n",
      "PaymentMethod        float64\n",
      "MonthlyCharges       float64\n",
      "TotalCharges         float64\n",
      "charge_per_tenure    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "tpot_data = tpot_data.astype({\"customerID\": float})\n",
    "print(tpot_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0453673",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae3bdce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tenure  PhoneService  Contract  PaymentMethod  MonthlyCharges  \\\n",
      "2    28.0           1.0       0.0            0.0           28.25   \n",
      "0    22.0           1.0       0.0            2.0           97.40   \n",
      "3    62.0           1.0       0.0            2.0          101.70   \n",
      "\n",
      "   TotalCharges  charge_per_tenure  \n",
      "2        250.90           8.960714  \n",
      "0        811.70          36.895455  \n",
      "3       3106.56          50.105806  \n",
      "Row 0 Predicted: 0.0, target: 2    0.0\n",
      "0    0.0\n",
      "3    0.0\n",
      "Name: customerID, dtype: float64\n",
      "Row 0 Predicted: 0.0, target:    tenure  PhoneService  Contract  PaymentMethod  MonthlyCharges  \\\n",
      "1     8.0           0.0       1.0            1.0           77.30   \n",
      "4    10.0           0.0       0.0            1.0           51.15   \n",
      "\n",
      "   TotalCharges  charge_per_tenure  \n",
      "1       1701.95          212.74375  \n",
      "4       3440.97          344.09700  \n"
     ]
    }
   ],
   "source": [
    "#spend 14+ hours on this...still thinking is wrong -- HELP!!!\n",
    "row = np.reshape(training_features, (3,7))\n",
    "results = exported_pipeline.predict(row)\n",
    "results\n",
    "print(row)\n",
    "print(f'Row 0 Predicted: {results[0]}, target: {training_target}')\n",
    "print(f'Row 0 Predicted: {results[0]}, target: {testing_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49db562",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533a1cd",
   "metadata": {},
   "source": [
    "The process for TPOT Classification & TPOT Regression were clear.       \n",
    "Train & Test data were accurate.            \n",
    "I really like the ability to export a template file for automation.             \n",
    "The only challenge was to get the data type correct.                    \n",
    "Even after change data type from string to float, the pipeline still recognizing a cell of an dropped column as a string. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "586ea5eb6d6a8e292d9d6a1aa5b97dd1961fe9a1ba5489fbc40f2fa2fa55a85d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
